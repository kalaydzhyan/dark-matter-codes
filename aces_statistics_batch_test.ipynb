{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math, sys, glob, re\n",
    "import scipy.constants as phco\n",
    "from aces_statistics import *\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "\"\"\" geocentric gravitational constant (m^3/s^2) \"\"\"\n",
    "GM = 3.986004418e14\n",
    "\"\"\" Earth radius (m) \"\"\"\n",
    "Rearth = 6378000\n",
    "\"\"\" Earth rotation (rad/s) \"\"\"\n",
    "wE = 7.292e-5\n",
    "\n",
    "current_path = !pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on session number  0\n",
      "Working on session number  1\n",
      "Working on session number  2\n",
      "Working on session number  3\n",
      "Working on session number  4\n",
      "Working on session number  5\n",
      "Working on session number  6\n",
      "Working on session number  7\n",
      "Working on session number  8\n",
      "Working on session number  9\n",
      "Working on session number  10\n",
      "Working on session number  11\n",
      "Working on session number  12\n",
      "Working on session number  13\n",
      "Working on session number  14\n",
      "Working on session number  15\n",
      "Working on session number  16\n",
      "Working on session number  17\n",
      "Working on session number  18\n",
      "Working on session number  19\n",
      "Working on session number  20\n",
      "Working on session number  21\n",
      "Working on session number  22\n",
      "Working on session number  23\n",
      "Working on session number  24\n",
      "Working on session number  25\n",
      "Working on session number  26\n",
      "Working on session number  27\n",
      "Working on session number  28\n",
      "Working on session number  29\n",
      "Working on session number  30\n",
      "Working on session number  31\n",
      "Working on session number  32\n",
      "Working on session number  33\n",
      "Working on session number  34\n",
      "Working on session number  35\n",
      "Working on session number  36\n",
      "Working on session number  37\n",
      "Working on session number  38\n",
      "Working on session number  39\n",
      "Working on session number  40\n",
      "Working on session number  41\n",
      "Working on session number  42\n",
      "Working on session number  43\n",
      "Working on session number  44\n",
      "Working on session number  45\n",
      "Working on session number  46\n",
      "Working on session number  47\n",
      "Working on session number  48\n",
      "Working on session number  49\n",
      "Working on session number  50\n",
      "Working on session number  51\n",
      "Working on session number  52\n",
      "Working on session number  53\n",
      "Working on session number  54\n",
      "Working on session number  55\n",
      "Working on session number  56\n",
      "Working on session number  57\n"
     ]
    }
   ],
   "source": [
    "\"\"\" This part of the code runs for several minutes, producing differences between theory and experiment for \n",
    "    all provided data. TODO: implement backup of the file before running, if previous version contained \n",
    "    significant amount of data. \"\"\"\n",
    "\n",
    "directories = glob.glob(current_path[0] + '/v4.3.2_mb_53896_53907/gs999/*')\n",
    "\n",
    "f = open('differences1.dat', 'w')\n",
    "f.write(\"# This file contains data for carrier and code (mean and STD), 3 frequencies each. The first number is the session number.\\n\")\n",
    "\n",
    "for dataset_number in range(len(directories)):\n",
    "    f.write(str(dataset_number)+\"\\t\")\n",
    "    print \"Working on session number \", dataset_number\n",
    "    \n",
    "    for carrier_code in [\"ca\", \"co\"]:\n",
    "        for frequency_n in [\"1\", \"2\", \"3\"]:\n",
    "            data1 = collect_data(dataset_number, carrier_code, frequency_n)\n",
    "            gs_orbit, iss_orbit = collect_trajectories(dataset_number)\n",
    "\n",
    "            data1[\"gs_positions\"] = map(lambda x: position_by_time(gs_orbit, x), data1['coord.time'])\n",
    "            data1[\"gs_velocities\"] = map(lambda x: velocity_by_time(gs_orbit, x), data1['coord.time'])\n",
    "            data1[\"iss_positions\"] = map(lambda x: position_by_time(iss_orbit, x), data1['coord.time'])\n",
    "            data1[\"iss_velocities\"] = map(lambda x: velocity_by_time(iss_orbit, x), data1['coord.time'])\n",
    "\n",
    "            data1 = relativistic_effect(data1, frequency_n)\n",
    "            \n",
    "            cutoff = min(len(data1['difference']), 250)\n",
    "            \n",
    "            mean_difference = np.mean(data1['difference'][: cutoff])\n",
    "            standard_deviation = np.std(data1['difference'][: cutoff])\n",
    "\n",
    "            f.write(str(mean_difference) + \"\\t\" + str(standard_deviation) + \"\\t\")\n",
    "    f.write(\"\\n\")\n",
    "        \n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "estimator for  ca  frequency  1  :  -1.53346964403e-16  +/-  3.738318063609927e-15\n",
      "estimator for  ca  frequency  2  :  -5.84388190477e-15  +/-  3.7105361987371075e-15\n",
      "estimator for  ca  frequency  3  :  -5.97065204363e-15  +/-  5.290844808229772e-15\n",
      "estimator for  co  frequency  1  :  -1.62561958368e-16  +/-  3.7532529565197865e-15\n",
      "estimator for  co  frequency  2  :  -5.85627863804e-15  +/-  3.752447133435046e-15\n",
      "estimator for  co  frequency  3  :  -5.96038046026e-15  +/-  5.259950060786446e-15\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Here we collect the generated data and form an unbiased minimal variance estimator \"\"\"\n",
    "\n",
    "filename = 'differences1.dat'\n",
    "data_differences = pd.read_csv(current_path[0] + '/' + filename, delim_whitespace = True, skiprows=1, \\\n",
    "                   names=['session', 'mean_ca_1', 'std_ca_1', 'mean_ca_2', 'std_ca_2', 'mean_ca_3', 'std_ca_3',\\\n",
    "                          'mean_co_1', 'std_co_1', 'mean_co_2', 'std_co_2', 'mean_co_3', 'std_co_3'])\n",
    "\n",
    "for carrier_code in [\"ca\", \"co\"]:\n",
    "        for frequency_n in [\"1\", \"2\", \"3\"]:\n",
    "            mean_name = 'mean_'+ carrier_code + '_' + frequency_n\n",
    "            std_name = 'std_'+ carrier_code + '_' + frequency_n\n",
    "            var_estimator = 1/np.sum(1/data_differences[std_name]**2)\n",
    "            estimator = var_estimator*np.sum(data_differences[mean_name]/data_differences[std_name]**2)\n",
    "            print 'estimator for ', carrier_code , ' frequency ', frequency_n, ' : ' , estimator, ' +/- ', np.sqrt(var_estimator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
